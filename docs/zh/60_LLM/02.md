# AI 问答

## AI 问答

实现 AI 问答非常容易。可以通过笔者的 `java-openai` 库调用 OpenAI 的 Chat 接口，将用户的问题发送给 GPT 模型，GPT 模型会返回推理结果。

## 临时记忆

临时记忆的实现有多种方式，这里简单介绍两种方法：

1. **数据库存储对话记录**：将用户和大模型的对话记录存入数据库中。当需要对新的问题进行推理时，将新消息和历史消息一起发送给大模型。这种方法的缺点是每次推理都会增加 token 数量。
2. **提示词汇总**：编写一个提示词，将用户的最新消息和历史记录放入提示词中。通过这个提示词，大模型会将新消息和历史消息汇总成一个最新的问题，再将这个问题交给大模型推理。此方法可以减少推理的 token 数量，但会增加一层模型调用。

## 长期记忆

长期记忆的实现相对复杂，这里介绍一种简单的方法：

1. 将用户的输入和大模型的输出添加到历史记录表中，并进行向量化处理。
2. 当用户有新的输入时，先对输入进行向量化，得到输入向量。然后将输入向量与历史记录中的向量进行余弦相似度计算，找到相似度较高的历史输入和输出。
3. 将相似度较高的历史输入和输出与最新的数据一起交给大模型推理，或者先让大模型汇总成一个输入，再让大模型进行推理。

这种方法有以下几个优点：

1. **减少 token 数量**：并不是所有历史输入和输出中的信息都与最新输入有关联。通过余弦相似度找到相似度较高的片段，可以减少 token 数量。
2. **理论上支持无限长的对话**：可以通过工程技术找出相似度最高的前 10 条或者前 100 条，理论上永远不会超出 token 限制。
