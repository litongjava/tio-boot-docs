# 向量检索

[[toc]]

## 项目目标

本项目旨在构建一个功能完备的 RAG（Retrieval-Augmented Generation）系统，主要目标包括：

- **知识库管理**：支持创建、更新和删除知识库，便于用户高效维护内容。
- **文档处理**：包括文档的拆分、片段的向量化处理，以提升检索效率和准确性。
- **问答系统**：提供高效的向量检索和实时生成回答的能力，支持复杂汇总类问题的处理。
- **系统优化**：通过统计分析和推理问答调试，不断优化系统性能和用户体验。

## 系统核心概念

在 RAG 系统中，以下是几个核心概念：

- **应用**：知识库的集合。每个应用可以自定义提示词，以满足不同的个性化需求。
- **知识库**：由多个文档组成，便于用户对内容进行分类和管理。
- **文档**：系统中对应的真实文档内容。
- **片段**：文档经过拆分后的最小内容单元，用于更高效的处理和检索。

## 功能实现步骤

1. **数据库设计** [查看 01.md](./01.md)  
   设计并实现项目所需的数据表结构与数据库方案，为后续的数据操作打下坚实基础。

2. **用户登录** [查看 02.md](./02.md)  
   实现了安全可靠的用户认证系统，保护用户数据并限制未经授权的访问。

3. **模型管理** [查看 03.md](./03.md)  
   支持针对不同平台的模型（如 OpenAI、Google Gemini、Claude）进行管理与配置。

4. **知识库管理** [查看 04.md](./04.md)  
   提供创建、更新及删除知识库的功能，方便用户维护与管理文档内容。

5. **文档拆分** [查看 05.md](./05.md)  
   可将文档拆分为多个片段，便于后续向量化和检索操作。

6. **片段向量** [查看 06.md](./06.md)  
   将文本片段进行向量化处理，以便进行语义相似度计算及高效检索。

7. **命中率测试** [查看 07.md](./07.md)  
   通过语义相似度和 Top-N 算法，检索并返回与用户问题最相关的文档片段，用于评估检索的准确性。

8. **文档管理** [查看 08.md](./08.md)  
   提供上传和管理文档的功能，上传后可自动拆分为片段便于进一步处理。

9. **片段管理** [查看 09.md](./09.md)  
   允许对已拆分的片段进行增、删、改、查等操作，确保内容更新灵活可控。

10. **问题管理** [查看 10.md](./10.md)  
    为片段指定相关问题，以提升检索时的准确性与关联度。

11. **应用管理** [查看 11.md](./11.md)  
    提供创建和配置应用（智能体）的功能，并可关联指定模型和知识库。

12. **向量检索** [查看 12.md](./12.md)  
    基于语义相似度，在知识库中高效检索与用户问题最匹配的片段。

13. **推理问答调试** [查看 13.md](./13.md)  
    提供检索与问答性能的评估工具，帮助开发者进行系统优化与调试。

14. **对话问答** [查看 14.md](./14.md)  
    为用户提供友好的人机交互界面，结合检索到的片段与用户问题实时生成回答。

15. **统计分析** [查看 15.md](./15.md)  
    对用户的提问与系统回答进行数据化分析，并以可视化图表的形式呈现系统使用情况。

16. **用户管理** [查看 16.md](./16.md)  
    提供多用户管理功能，包括用户的增删改查及权限控制。

17. **API 管理** [查看 17.md](./17.md)  
    对外提供标准化 API，便于外部系统集成和调用本系统的功能。

18. **存储文件到 S3** [查看 18.md](./18.md)  
    将用户上传的文件存储至 S3 等对象存储平台，提升文件管理的灵活性与可扩展性。

19. **文档解析优化** [查看 19.md](./19.md)  
    介绍与对比常见的文档解析方案，并提供提升文档解析速度和准确性的优化建议。

20. **片段汇总** [查看 20.md](./20.md)  
    对片段内容进行汇总，以提升总结类问题的查询与回答效率。

21. **文档多分块与检索** [查看 21.md](./21.md)  
    将片段进一步拆分为句子并进行向量检索，提升检索的准确度与灵活度。

22. **多文档支持** [查看 22.md](./22.md)  
    兼容多种文档格式，包括 `.doc`, `.docx`, `.xls`, `.xlsx`, `.ppt`, `.pptx` 等。

23. **对话日志** [查看 23.md](./23.md)  
    记录并展示对话日志，用于后续分析和问题回溯。

24. **检索性能优化** [查看 24.md](./24.md)  
    提供整库扫描和分区检索等多种方式，进一步提高检索速度和效率。

25. **Milvus** [查看 25.md](./25.md)  
    将向量数据库切换至 Milvus，以在大规模向量检索场景中获得更佳的性能与可扩展性。

26. **文档解析方案和费用对比** [查看 26.md](./26.md)  
    对比不同文档解析方案在成本、速度、稳定性等方面的差异，为用户提供更加经济高效的选择。

27. **爬取网页数据** [查看 27.md](./27.md)  
    支持从网页中抓取所需内容，后续处理流程与本地文档一致：分段、向量化、存储与检索。

## 核心功能

本节完成:

- **向量检索**：从数据库中检索出语义相似的向量片段。
- **推理问答**：基于搜索片段及用户问题生成自动化回答。

---

## 片段搜索功能

### 数据传输对象 (VO)

#### `ParagraphSearchResultVo`

```java
package com.litongjava.maxkb.vo;

import lombok.AllArgsConstructor;
import lombok.Data;
import lombok.NoArgsConstructor;
import lombok.experimental.Accessors;

@Data
@NoArgsConstructor
@AllArgsConstructor
@Accessors(chain = true)
public class ParagraphSearchResultVo {
  private Long id;
  private String content, title;
  private Long dataset_id;
  private String dataset_name;
  private Long document_id;
  private String document_name;
  private String document_type;
  private String document_url;
  private Long paragraph_id;

  private Boolean active;
  private Integer hit_num;
  private String status;

  public ParagraphSearchResultVo(long id, String content, String document_name, long document_id) {
    this.id = id;
    this.content = content;
    this.document_name = document_name;
    this.document_id = document_id;
  }
}
```

- 封装了片段搜索的结果，包括片段的基本信息及所属文档和数据集的相关信息。
- 使用 Lombok 注解简化代码。

---

### 搜索服务实现

#### `MaxKbParagraphSearchService`

```java
package com.litongjava.maxkb.service;

import java.util.ArrayList;
import java.util.Arrays;
import java.util.List;

import com.litongjava.db.activerecord.Db;
import com.litongjava.db.activerecord.Row;
import com.litongjava.jfinal.aop.Aop;
import com.litongjava.maxkb.vo.ParagraphSearchResultVo;
import com.litongjava.openai.consts.OpenAiModels;
import com.litongjava.template.SqlTemplates;

import lombok.extern.slf4j.Slf4j;

@Slf4j
public class MaxKbParagraphSearchService {

  public List<ParagraphSearchResultVo> search(Long[] datasetIdArray, Float similarity, Integer top_n, String question) {
    Long vectorId = Aop.get(MaxKbEmbeddingService.class).getVectorId(question, OpenAiModels.text_embedding_3_large);

    String sql = SqlTemplates.get("kb.search_paragraph_with_dataset_ids");

    log.info("search_paragraph:{},{},{},{}", vectorId, Arrays.toString(datasetIdArray), similarity, top_n);

    List<Row> records = Db.find(sql, vectorId, datasetIdArray, similarity, top_n);

    List<ParagraphSearchResultVo> results = new ArrayList<>();
    for (Row row : records) {
      ParagraphSearchResultVo vo = row.toBean(ParagraphSearchResultVo.class);
      results.add(vo);
    }
    return results;
  }
}
```

- **向量生成**：调用`MaxKbEmbeddingService`生成问题向量。
- **SQL 查询**：从`SqlTemplates`加载查询模板并执行搜索。
- **结果封装**：将查询结果转换为`ParagraphSearchResultVo`列表，供前端使用。

---

### 单元测试

#### `MaxKbParagraphSearchServiceTest`

```java
package com.litongjava.maxkb.service;

import java.util.List;

import org.junit.Test;

import com.litongjava.jfinal.aop.Aop;
import com.litongjava.maxkb.config.DbConfig;
import com.litongjava.maxkb.vo.ParagraphSearchResultVo;
import com.litongjava.tio.boot.testing.TioBootTest;
import com.litongjava.tio.utils.json.JsonUtils;

public class MaxKbParagraphSearchServiceTest {

  @Test
  public void test() {
    TioBootTest.runWith(DbConfig.class);

    Long[] datasetIdArray = { 446225135519784960L };
    Float similarity = 0.2f;
    Integer top_n = 3;
    String question = "office hour";

    List<ParagraphSearchResultVo> result = Aop.get(MaxKbParagraphSearchService.class).search(datasetIdArray, similarity, top_n, question);

    System.out.println(JsonUtils.toJson(result));
  }
}
```

- 验证搜索功能的正确性。
- 定义测试用例参数并输出搜索结果的 JSON 表示。

---

## 搜索逻辑与 SQL 解析

### 搜索逻辑

1. 接收用户查询并向量化。
2. 构建 SQL 查询以获取相关片段。
3. 根据相似度排序结果并限制返回数量。
4. 返回封装后的结果。

---

### SQL 查询模板

```sql
--# kb.search_paragraph_with_dataset_ids
SELECT
  sub.id,
  sub.content,
  sub.title,
  sub.status,
  sub.hit_num,
  sub.is_active,
  sub.dataset_id,
  sub.document_id,
  sub.dataset_name,
  sub.document_name,
  sub.similarity,
  sub.similarity AS comprehensive_score
FROM (
  SELECT
    d.name AS document_name,
    ds.name AS dataset_name,
    p.id,
    p.content,
    p.title,
    p.status,
    p.hit_num,
    p.is_active,
    p.dataset_id,
    p.document_id,
    (1 - (p.embedding <=> c.v)) AS similarity
  FROM
    max_kb_paragraph p
  JOIN
    max_kb_document d ON p.document_id = d.id
  JOIN
    max_kb_dataset ds ON p.dataset_id = ds.id
  JOIN
    max_kb_embedding_cache c ON c.id = ?
  WHERE
    p.is_active = TRUE
    AND p.deleted = 0
    AND ds.deleted = 0
    AND p.dataset_id = ANY (?)
) sub
WHERE
  sub.similarity > ?
ORDER BY
  sub.similarity DESC
LIMIT ?;
```

- **子查询**：通过关联片段、文档、数据集及向量缓存表计算相似度。
- **过滤**：只返回激活且未删除的片段。
- **排序与限制**：按相似度降序排列，并限制返回数量。

---

### 结果解析示例

```json
[
  {
    "id": "446228832295108608",
    "content": "I reserve the right to be offline after 6 pm and on Saturdays...",
    "dataset_name": "ICS 111",
    "document_name": "ICS111_31391_Miller_Syllabus_F24.pdf",
    "similarity": 0.85
  },
  ...
]
```

- **字段**：
  - `id`：片段 ID。
  - `content`：片段内容。
  - `similarity`：片段与问题的相似度。
  - `dataset_name` 和 `document_name`：片段所属数据集和文档。

---

## 推理功能实现

### 数据交互流程

1. 获取用户问题。
2. 搜索相关片段。
3. 构造提示词并请求大语言模型。
4. 返回问答结果。

### 示例提示词模板

```text
用户问题：{question}
相关片段：
1. {content1}
2. {content2}
...
请根据以上信息生成回答：
```

---

### 大语言模型处理

调用模型接口，传入用户问题和片段信息，生成回答。下一节将获详细介绍

---

## 总结

通过实现片段搜索与推理问答，系统能够提供高效且智能的问答服务。未来可扩展功能包括：

- 增强多语言支持。
- 提高嵌入模型的准确性。
- 实现更复杂的上下文推理能力。
