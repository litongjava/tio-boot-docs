# 检索性能优化

[[toc]]

## 项目目标

本项目旨在构建一个功能完备的 RAG（Retrieval-Augmented Generation）系统，主要目标包括：

- **知识库管理**：支持创建、更新和删除知识库，便于用户高效维护内容。
- **文档处理**：包括文档的拆分、片段的向量化处理，以提升检索效率和准确性。
- **问答系统**：提供高效的向量检索和实时生成回答的能力，支持复杂汇总类问题的处理。
- **系统优化**：通过统计分析和推理问答调试，不断优化系统性能和用户体验。

## 系统核心概念

在 RAG 系统中，以下是几个核心概念：

- **应用**：知识库的集合。每个应用可以自定义提示词，以满足不同的个性化需求。
- **知识库**：由多个文档组成，便于用户对内容进行分类和管理。
- **文档**：系统中对应的真实文档内容。
- **片段**：文档经过拆分后的最小内容单元，用于更高效的处理和检索。

## 功能实现步骤

1. **数据库设计** [查看 01.md](./01.md)  
   设计并实现项目所需的数据表结构与数据库方案，为后续的数据操作打下坚实基础。

2. **用户登录** [查看 02.md](./02.md)  
   实现了安全可靠的用户认证系统，保护用户数据并限制未经授权的访问。

3. **模型管理** [查看 03.md](./03.md)  
   支持针对不同平台的模型（如 OpenAI、Google Gemini、Claude）进行管理与配置。

4. **知识库管理** [查看 04.md](./04.md)  
   提供创建、更新及删除知识库的功能，方便用户维护与管理文档内容。

5. **文档拆分** [查看 05.md](./05.md)  
   可将文档拆分为多个片段，便于后续向量化和检索操作。

6. **片段向量** [查看 06.md](./06.md)  
   将文本片段进行向量化处理，以便进行语义相似度计算及高效检索。

7. **命中率测试** [查看 07.md](./07.md)  
   通过语义相似度和 Top-N 算法，检索并返回与用户问题最相关的文档片段，用于评估检索的准确性。

8. **文档管理** [查看 08.md](./08.md)  
   提供上传和管理文档的功能，上传后可自动拆分为片段便于进一步处理。

9. **片段管理** [查看 09.md](./09.md)  
   允许对已拆分的片段进行增、删、改、查等操作，确保内容更新灵活可控。

10. **问题管理** [查看 10.md](./10.md)  
    为片段指定相关问题，以提升检索时的准确性与关联度。

11. **应用管理** [查看 11.md](./11.md)  
    提供创建和配置应用（智能体）的功能，并可关联指定模型和知识库。

12. **向量检索** [查看 12.md](./12.md)  
    基于语义相似度，在知识库中高效检索与用户问题最匹配的片段。

13. **推理问答调试** [查看 13.md](./13.md)  
    提供检索与问答性能的评估工具，帮助开发者进行系统优化与调试。

14. **对话问答** [查看 14.md](./14.md)  
    为用户提供友好的人机交互界面，结合检索到的片段与用户问题实时生成回答。

15. **统计分析** [查看 15.md](./15.md)  
    对用户的提问与系统回答进行数据化分析，并以可视化图表的形式呈现系统使用情况。

16. **用户管理** [查看 16.md](./16.md)  
    提供多用户管理功能，包括用户的增删改查及权限控制。

17. **API 管理** [查看 17.md](./17.md)  
    对外提供标准化 API，便于外部系统集成和调用本系统的功能。

18. **存储文件到 S3** [查看 18.md](./18.md)  
    将用户上传的文件存储至 S3 等对象存储平台，提升文件管理的灵活性与可扩展性。

19. **文档解析优化** [查看 19.md](./19.md)  
    介绍与对比常见的文档解析方案，并提供提升文档解析速度和准确性的优化建议。

20. **片段汇总** [查看 20.md](./20.md)  
    对片段内容进行汇总，以提升总结类问题的查询与回答效率。

21. **文档多分块与检索** [查看 21.md](./21.md)  
    将片段进一步拆分为句子并进行向量检索，提升检索的准确度与灵活度。

22. **多文档支持** [查看 22.md](./22.md)  
    兼容多种文档格式，包括 `.doc`, `.docx`, `.xls`, `.xlsx`, `.ppt`, `.pptx` 等。

23. **对话日志** [查看 23.md](./23.md)  
    记录并展示对话日志，用于后续分析和问题回溯。

24. **检索性能优化** [查看 24.md](./24.md)  
    提供整库扫描和分区检索等多种方式，进一步提高检索速度和效率。

25. **Milvus** [查看 25.md](./25.md)  
    将向量数据库切换至 Milvus，以在大规模向量检索场景中获得更佳的性能与可扩展性。

26. **文档解析方案和费用对比** [查看 26.md](./26.md)  
    对比不同文档解析方案在成本、速度、稳定性等方面的差异，为用户提供更加经济高效的选择。

27. **爬取网页数据** [查看 27.md](./27.md)  
    支持从网页中抓取所需内容，后续处理流程与本地文档一致：分段、向量化、存储与检索。

## 根据 `dataset_id` 对 `max_kb_paragraph` 表进行分区

要根据 `dataset_id` 对 `max_kb_paragraph` 表进行分区，可以使用 PostgreSQL 的 **分区表** 功能。根据 `dataset_id` 的数据分布情况，可以选择 **哈希分区**、**列表分区** 或 **范围分区**。以下是使用 **哈希分区** 和 **列表分区** 的两种实现方式。

### 1. 使用哈希分区

哈希分区适用于 `dataset_id` 分布较为均匀且没有特定分组需求的情况。以下是具体步骤：

#### 步骤 1：创建分区表

首先，创建一个分区表，并指定按 `dataset_id` 进行哈希分区。例如，使用 4 个分区：

```sql
DROP TABLE IF EXISTS max_kb_paragraph;

CREATE TABLE max_kb_paragraph (
  id BIGINT PRIMARY KEY,
  source_id BIGINT NOT NULL,
  source_type VARCHAR NOT NULL,
  content VARCHAR NOT NULL,
  title VARCHAR NOT NULL,
  status VARCHAR NOT NULL,
  hit_num INT NOT NULL,
  is_active BOOLEAN NOT NULL,
  embedding VECTOR NOT NULL, -- 使用 pgvector 类型
  meta JSONB NOT NULL,
  dataset_id BIGINT NOT NULL,
  document_id BIGINT NOT NULL,
  paragraph_id BIGINT,
  search_vector TSVECTOR,
  creator VARCHAR(64) DEFAULT '',
  create_time TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT CURRENT_TIMESTAMP,
  updater VARCHAR(64) DEFAULT '',
  update_time TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT CURRENT_TIMESTAMP,
  deleted SMALLINT DEFAULT 0,
  tenant_id BIGINT NOT NULL DEFAULT 0
) PARTITION BY HASH (dataset_id);
```

#### 步骤 2：创建分区

接下来，创建具体的分区表。例如，创建 4 个分区：

```sql
CREATE TABLE max_kb_paragraph_p0 PARTITION OF max_kb_paragraph
  FOR VALUES WITH (MODULUS 4, REMAINDER 0);

CREATE TABLE max_kb_paragraph_p1 PARTITION OF max_kb_paragraph
  FOR VALUES WITH (MODULUS 4, REMAINDER 1);

CREATE TABLE max_kb_paragraph_p2 PARTITION OF max_kb_paragraph
  FOR VALUES WITH (MODULUS 4, REMAINDER 2);

CREATE TABLE max_kb_paragraph_p3 PARTITION OF max_kb_paragraph
  FOR VALUES WITH (MODULUS 4, REMAINDER 3);
```

### 2. 使用列表分区

如果 `dataset_id` 有特定的分组需求或数量较少，可以使用列表分区。以下是具体步骤：

#### 步骤 1：创建分区表

创建一个按 `dataset_id` 进行列表分区的表：

```sql
DROP TABLE IF EXISTS max_kb_paragraph;

CREATE TABLE max_kb_paragraph (
  id BIGINT PRIMARY KEY,
  source_id BIGINT NOT NULL,
  source_type VARCHAR NOT NULL,
  content VARCHAR NOT NULL,
  title VARCHAR NOT NULL,
  status VARCHAR NOT NULL,
  hit_num INT NOT NULL,
  is_active BOOLEAN NOT NULL,
  embedding VECTOR NOT NULL, -- 使用 pgvector 类型
  meta JSONB NOT NULL,
  dataset_id BIGINT NOT NULL,
  document_id BIGINT NOT NULL,
  paragraph_id BIGINT,
  search_vector TSVECTOR,
  creator VARCHAR(64) DEFAULT '',
  create_time TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT CURRENT_TIMESTAMP,
  updater VARCHAR(64) DEFAULT '',
  update_time TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT CURRENT_TIMESTAMP,
  deleted SMALLINT DEFAULT 0,
  tenant_id BIGINT NOT NULL DEFAULT 0
) PARTITION BY LIST (dataset_id);
```

#### 步骤 2：创建分区

假设有特定的 `dataset_id` 值，例如 `1, 2, 3, 4`，可以为每个值创建一个分区：

```sql
CREATE TABLE max_kb_paragraph_dataset1 PARTITION OF max_kb_paragraph
  FOR VALUES IN (1);

CREATE TABLE max_kb_paragraph_dataset2 PARTITION OF max_kb_paragraph
  FOR VALUES IN (2);

CREATE TABLE max_kb_paragraph_dataset3 PARTITION OF max_kb_paragraph
  FOR VALUES IN (3);

CREATE TABLE max_kb_paragraph_dataset4 PARTITION OF max_kb_paragraph
  FOR VALUES IN (4);
```

对于未列出的 `dataset_id`，可以创建一个默认分区：

```sql
CREATE TABLE max_kb_paragraph_default PARTITION OF max_kb_paragraph
  DEFAULT;
```

### 选择合适的分区策略

- **哈希分区**：适用于 `dataset_id` 分布均匀且不需要按特定值进行查询优化的情况。分区数量需要根据实际数据量和查询性能需求进行调整。
- **列表分区**：适用于 `dataset_id` 值较少且已知的情况，可以按特定值进行优化，但当 `dataset_id` 数量较多或动态变化时，维护成本较高。

### 注意事项

1. **索引和约束**：在分区表上创建索引和约束时，需要在每个分区上单独创建，或者使用分区约束排除。
2. **查询优化**：确保查询中包含 `dataset_id` 以利用分区裁剪（partition pruning）提升性能。
3. **维护分区**：根据数据增长情况，定期添加新的分区以适应新的 `dataset_id` 值。

通过上述步骤，您可以根据 `dataset_id` 对 `max_kb_paragraph` 表进行有效的分区，从而提升查询性能和数据管理的灵活性。

### 查询

#### 1. 使用列表分区时，查询是针对主表还是针对子表进行的？

**查询目标：主表**

- **查询主表**：在 PostgreSQL 中，无论使用何种分区策略（列表分区、哈希分区、范围分区等），所有的查询都是针对**主表（父表）**发起的。主表本身不存储数据，而是作为分区的入口，负责将查询路由到相应的子分区表。

- **自动分区裁剪（Partition Pruning）**：当查询中包含分区键（在您的例子中是 `dataset_id`）时，PostgreSQL 会自动识别并只访问相关的子分区表，从而提高查询性能。例如：

  ```sql
  SELECT * FROM max_kb_paragraph WHERE dataset_id = 2;
  ```

  上述查询会自动路由到 `max_kb_paragraph_dataset2` 分区，而不需要扫描其他分区。

- **查询不包含分区键**：如果查询中不包含分区键，PostgreSQL 可能需要扫描所有相关的子分区，这可能会影响性能。因此，尽量在查询中包含分区键以利用分区裁剪的优势。

**总结**：无论是插入、更新还是查询操作，您都只需要针对**主表**执行操作，PostgreSQL 会根据分区策略自动处理具体的子表。
