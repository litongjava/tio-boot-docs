# HTTP/1.1 Pipelining 性能测试报告

本文通过使用 `wrk` 工具对开启和关闭 HTTP/1.1 pipeline 时服务器的性能进行对比测试。

## 测试环境

- **工具**: `wrk`
- **测试地址**: `http://127.0.0.1:8080/plaintext`
- **测试时长**: 60 秒
- **线程数**: 4
- **并发连接数**: 256
- **超时时间**: 8 秒

## 开启 Pipeline 测试

### 脚本 (`pipeline.lua`)

```lua
init = function(args)
  local r = {}
  local depth = tonumber(args[1]) or 1
  for i=1, depth do
    r[i] = wrk.format()
  end
  req = table.concat(r)
end

request = function()
  return req
end
```

### 执行命令

```shell
wrk \
  -H "Host: 127.0.0.1" \
  -H "Accept: text/plain" \
  -H "Connection: keep-alive" \
  --latency \
  -d 60s \
  -c 256 \
  --timeout 8 \
  -t 4 \
  http://127.0.0.1:8080/plaintext \
  -s pipeline.lua \
  -- 100
```

### 测试结果

```
Running 1m test @ http://127.0.0.1:8080/plaintext
  4 threads and 256 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency    67.69ms   78.02ms   1.36s    57.96%
    Req/Sec    55.53k    10.64k   68.91k    89.78%
  Latency Distribution
     50%  116.98ms
     75%    0.00us
     90%    0.00us
     99%    0.00us
  13237723 requests in 1.00m, 1.82GB read
Requests/sec: 220306.50
Transfer/sec:     31.09MB
```

- **每秒请求数**: 220,306.50
- **数据传输速率**: 31.09 MB/sec

## 关闭 Pipeline 测试

### 执行命令

```shell
wrk \
  -H "Host: 127.0.0.1" \
  -H "Accept: text/plain" \
  -H "Connection: keep-alive" \
  --latency \
  -d 60s \
  -c 256 \
  -t 4 \
  http://127.0.0.1:8080/plaintext
```

### 测试结果

```
Running 1m test @ http://127.0.0.1:8080/plaintext
  4 threads and 256 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency     2.50ms    2.66ms  63.27ms   90.78%
    Req/Sec    16.26k     6.97k   50.24k    73.52%
  Latency Distribution
     50%    1.78ms
     75%    3.01ms
     90%    4.96ms
     99%   13.65ms
  3874685 requests in 1.00m, 461.90MB read
Requests/sec:  64493.99
Transfer/sec:      7.69MB
```

- **每秒请求数**: 64,493.99
- **数据传输速率**: 7.69 MB/sec

## 测试结论

通过上述对比可以看出：

- 在开启 HTTP/1.1 pipeline 后，请求的吞吐量明显提升。
- Pipeline 模式下，每秒请求数提升至 220,306.50，比关闭 Pipeline 模式下的 64,493.99 高出约 3.4 倍。
- 数据传输速率也显著提高，从 7.69 MB/sec 增加到 31.09 MB/sec。

因此，在服务器端能够稳定支持 HTTP/1.1 pipeline 时，开启 pipeline 可显著提高并发处理性能，增强系统吞吐能力。
